id,paper,pdf,date,tags,arxiv,paperswithcode
1,Adaptive Risk Minimization: A Meta-Learning Approach for Tackling Group Shift,adaptive_risk_minimization,20/07/20,Meta Learning,https://arxiv.org/abs/2007.02931,https://paperswithcode.com/paper/adaptive-risk-minimization-a-meta-learning
2,Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks,cycle_gan,23/07/20,GAN,https://arxiv.org/abs/1703.10593,https://paperswithcode.com/paper/unpaired-image-to-image-translation-using
3,Unsupervised Learning of Visual Features by Contrasting Cluster Assignments,swav,30/07/20,Self-Supervised Learning,https://arxiv.org/abs/2006.09882,https://paperswithcode.com/paper/unsupervised-learning-of-visual-features-by
4,What Should Not Be Contrastive in Contrastive Learning,what_should_not_be_contrastive_in_constrative_learning,19/08/20,Self-Supervised Learning,https://arxiv.org/abs/2008.05659,https://paperswithcode.com/paper/what-should-not-be-contrastive-in-contrastive
5,Axial-DeepLab: Stand-Alone Axial-Attention for Panoptic Segmentation,axial_deeplab,29/08/20,Segmentation,https://arxiv.org/abs/2003.07853,https://paperswithcode.com/paper/axial-deeplab-stand-alone-axial-attention-for
6,What is being transferred in transfer learning?,what_is_being_transferred_in_transfer_learning,08/09/20,"Explainability, Interpretability",https://arxiv.org/abs/2008.11687,https://paperswithcode.com/paper/what-is-being-transferred-in-transfer
7,Supervised Contrastive Learning,supervised_contrastive_learning,16/09/20,Supervised Learning,https://arxiv.org/abs/2004.11362,https://paperswithcode.com/paper/supervised-contrastive-learning
8,Flow-edge Guided Video Completion,flowedge_guided_video_completion,28/09/20,Supervised Learning,https://arxiv.org/abs/2009.01835,https://paperswithcode.com/paper/flow-edge-guided-video-completion
9,An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale,an_image_is_worth_16x16_words_transformers_for_image_recognition_at_scale,07/10/20,"Supervised Learning, Transformers",https://arxiv.org/abs/2010.11929,https://paperswithcode.com/paper/an-image-is-worth-16x16-words-transformers-1
10,Do Language Embeddings Capture Scales?,do_language_embeddings_capture_scales,19/10/20,NLP,https://arxiv.org/abs/2010.05345,https://paperswithcode.com/paper/do-language-embeddings-capture-scales
11,Are all negatives created equal in contrastive instance discrimination?,are_all_negatives_created_equal_for_CID,27/10/20,Self-Supervised Learning,https://arxiv.org/abs/2010.06682,https://paperswithcode.com/paper/are-all-negatives-created-equal-in-1
12,Is Batch Norm unique? An empirical investigation and prescription to emulate the best properties of common normalizers without batch dependence,is_batchnorm_unique,16/11/20,Supervised Learning,https://arxiv.org/abs/2010.10687,https://paperswithcode.com/paper/is-batch-norm-unique-an-empirical
13,CoMatch: Semi-supervised Learning with Contrastive Graph Regularization,comatch,02/12/20,Semi-Supervised Learning,https://arxiv.org/abs/2011.11183,https://paperswithcode.com/paper/comatch-semi-supervised-learning-with
14,Scaling down Deep Learning,scaling_down_deeplearning,15/12/20,Supervised Learning,https://arxiv.org/abs/2011.14439,https://paperswithcode.com/paper/scaling-down-deep-learning
15,EfficientNetv2,efficientnet_v2,05/04/21,Supervised Learning,https://arxiv.org/abs/2104.00298,https://paperswithcode.com/paper/efficientnetv2-smaller-models-and-faster
16,SpeechStew,speech_stew,18/04/21,Supervised Learning,https://arxiv.org/abs/2104.02133,https://paperswithcode.com/paper/speechstew-simply-mix-all-available-speech
17,Emerging Properties in Self-Supervised Vision Transformers,emerging_properties_in_self_supervised_vit,23/05/21,"Self-Supervised Learning, Transformers",https://arxiv.org/abs/2104.14294,https://paperswithcode.com/paper/emerging-properties-in-self-supervised-vision